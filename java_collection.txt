LinkedList
============
public class LinkedList<E>
    extends AbstractSequentialList<E>
    implements List<E>, Deque<E>, Cloneable, java.io.Serializable
	
 a LinkedList stores its data as a list of elements and every element is linked to its previous and next element. In this case, the search operation for an item has execution time equal to O(n).

The insertion, addition and removal operations of an item are faster in a LinkedList because there is no need to resize an array or update the index when an element is added to some arbitrary position inside the collection.

A LinkedList consumes more memory than an ArrayList because of every node in a LinkedList stores two references, one for its previous element and one for its next element, whereas ArrayList holds only data and its index.

LinkedList implements List and Deque interface.(add() and addAll() from list while addFirst(), addLast(),removeFirst() and removeLast() from Deque).
removeFirstOccurence()
removeLastOccurence()

Queue operations
linkedList.poll(); // throw NoSuchElementException() on 
linkedList.pop(); // return null if list is empty
linkedList.push(Object o); //inserts the element as the head of the collection.










ArrayList
==========
public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable
		
An ArrayList is an index based data structure backed by an Array. It provides random access to its elements with a performance equal to O(1).
able to dynamically grow and shrink as you add/remove elements.
Random access takes O(1) time
Adding element takes amortized constant time O(1)
Inserting/Deleting takes O(n) time
Searching takes O(n) time for unsorted array and O(log n) for a sorted one

indexOf() or lastIndexOf()  - return index of Object 

If you have a sorted array, then you may use a binary search algorithm which works faster than linear search
Collections.sort(list);
int index = Collections.binarySearch(list, "f");

list.remove(0); // it will remove index 0  element
list.remove(Integer.valueOf(0)); // it will remove element 0, not index 0 element

By using Itertor we can remove element
Iterator<String> it = stringsToSearch.iterator();
while (it.hasNext()) {
    if (matchingStrings.contains(it.next())) {
        it.remove();
    }
}




Immutable ArrayList
====================
List<String> unmodifiableList = Collections.unmodifiableList(list);
    unmodifiableList.add("four");// will throw UnsupportedOperationException.class


Multi Dimensional ArrayList
===========================
ArrayList<ArrayList<Integer>> graph = new ArrayList<>();
ArrayList<ArrayList<ArrayList<String>>> space = new ArrayList<>();



Converting Iterator to List
===========================
Iterator<Integer> iterator = Arrays.asList(1, 2, 3).iterator();
List<Integer> actualList = new ArrayList<Integer>();
while (iterator.hasNext()) {
    actualList.add(iterator.next());
}

List<Integer> actualList = new ArrayList<Integer>();
iterator.forEachRemaining(actualList::add); // java 8

Iterable<Integer> iterable = () -> iterator;
List<Integer> actualList = StreamSupport
  .stream(iterable.spliterator(), false)
  .collect(Collectors.toList()); // using java 8 streaming 
  
 Duplicate remove on list
 List<Integer> listWithoutDuplicates = listWithDuplicates.stream()
     .distinct()
     .collect(Collectors.toList());
	 

Check If Two Lists are Equal in Java

List<String> list1 = Arrays.asList("1", "2", "3", "4");
List<String> list2 = Arrays.asList("1", "2", "3", "4");
Assert.assertEquals(list1, list2);


How to Find an Element in a List with Java
    The contains method
    The indexOf method
    An ad-hoc for loop, and
    The Stream API
	
Java List UnsupportedOperationException
========================================
A frequent way in which this error occurs is when we use asList() method from java.util.Arrays:
public static List asList(T... a)
It returns:
    a fixed-size List as of size of a given array
    an element of the same type as the one in the original array and it must be an Object
    elements in the same order as in original array
    a list that is serializable and implements RandomAccess
Since T is a varargs, we can pass an array or the items directly as parameters, and the method will create a fixed-size initialized list:
List<String> flowers = Arrays.asList("Ageratum", "Allium", "Poppy", "Catmint");
String[] flowers = { "Ageratum", "Allium", "Poppy", "Catmint" };
List<String> flowerList = Arrays.asList(flowers);
Since the returned List is a fixed-size List, we can’t add/remove elements.
An attempt to add more elements would cause UnsupportedOperationException:
String[] flowers = { "Ageratum", "Allium", "Poppy", "Catmint" }; 
List<String> flowerList = Arrays.asList(flowers); 
flowerList.add("Celosia");

The root of this Exception is that the returned object doesn't implement the add() operation since it isn't the same as java.util.ArrayList.

It's an ArrayList, from java.util.Arrays.(This ArrayList internally use that array which is final variable ,so we can't modify that array ,as like inside string internally use final charcter array)

Another way to obtain the same exception is by trying to remove an element from the obtained list.

On the other hand, there are ways to obtain a mutable List in case we need it.

String[] flowers = { "Ageratum", "Allium", "Poppy", "Catmint" }; 
List<String> flowerList = new ArrayList<>(Arrays.asList(flowers));

Copy a List to Another List in Java
====================================
Constructor
-----------
A simple way to copy a List is by using the constructor that takes a collection as its argument:
List<Plant> copy = new ArrayList<>(list);
Due to the fact that we're copying reference here and not cloning the objects,  every amends made in one element will affect both lists.
For that reason, using the constructor is good to copy immutable objects:
List<Integer> copy = new ArrayList<>(list);
Integer is an immutable class, its value is set when the instance is created and can never change.
An Integer reference can thus be shared by multiple lists and threads and there's no way anybody can change its value.
List ConcurrentAccessException
----------------------------------
A common problem working with lists is the ConcurrentAccessException. This could mean that we're modifying the list while we're trying to copy it, most likely in another thread.

To fix this issue we have to either:
    Use a designed for concurrent access collection ( in this case use CopyOnWhiteArrayList)
    Lock the collection appropriately to iterate over it . ( in this case use ReentrantReadWriteLock.)
    Find a way to avoid needing to copy the original collection

AddAll
--------
List<Integer> copy = new ArrayList<>();
copy.addAll(list)
In this case also,contents of both lists will reference the same objects

Collections.copy
-----------------
List<Integer> source = Arrays.asList(1, 2, 3);
		List<Integer> dest = Arrays.asList(5, 6, 7, 8, 9, 10);
		Collections.copy(dest, source);
Just the three first items were overwritten while the rest of the elements in the list are conserved.

List<String> copy = list.stream()
  .collect(Collectors.toList()); // using java 8 
  
Remove All Occurrences of a Specific Value from a List
======================================================
Using a while Loop
Removing Until the List Changes .//  while (list.remove(element));
Using an Iterator
using stream. // list.stream().filter(e -> !Objects.equals(e, element))    .collect(Collectors.toList());
using removeIf // list.removeIf(n -> Objects.equals(n, element));

ListIterator
-------------
A ListIterator allows us to traverse a list of elements in either forward or backward order.
ListIterator<String> listIterator = countries.listIterator();

Intersection of Two Lists of Strings
------
Set<String> result = list.stream()
  .distinct()
  .filter(otherList::contains)
  .collect(Collectors.toSet());
  
  





HashSet
=======
public class HashSet<E>
    extends AbstractSet<E>
    implements Set<E>, Cloneable, java.io.Serializable

    It stores unique elements and permits nulls
    It's backed by a HashMap
    It doesn't maintain insertion order
    It's not thread-safe

When we put an object into a HashSet, it uses the object's hashcode value to determine if an element is not in the set already.
Each hash code value corresponds to a certain bucket location which can contain various elements, for which the calculated hash value is the same. But two objects with the same hashCode might not be equal.
So, objects within the same bucket will be compared using the equals() method.

The performance of a HashSet is affected mainly by two parameters – its Initial Capacity and the Load Factor.
The expected time complexity of adding an element to a set is O(1) which can drop to O(n) in the worst case scenario (only one bucket present) – therefore, it's essential to maintain the right HashSet's capacity.

A low initial capacity reduces space complexity but increases the frequency of rehashing which is an expensive process.
On the other hand, a high initial capacity increases the cost of iteration and the initial memory consumption.

As a rule of thumb:
    A high initial capacity is good for a large number of entries coupled with little to no iteration
    A low initial capacity is good for few entries with a lot of iteration






TreeSet
=======
public class HashSet<E>
    extends AbstractSet<E>
    implements Set<E>, Cloneable, java.io.Serializable


    It stores unique elements
    It doesn't preserve the insertion order of the elements
    It sorts the elements in ascending order
    It's not thread-safe

The TreeSet uses a self-balancing binary search tree, more specifically a Red-Black tree.

Set<String> treeSet = new TreeSet<>(Comparator.comparing(String::length));

The add() method, as expected, can be used for adding elements to a TreeSet. If an element was added, the method returns true, otherwise – false.
The contract of the method states that an element will be added only when the same isn't already present in the Set.

methods
-------
first()
last()
subSet() //return the elements ranging from fromElement to toElement. Note that fromElement is inclusive and toElement is exclusive
headSet() //return elements of TreeSet which are smaller than the specified element
tailSet()//return the elements of a TreeSet which are greater than or equal to the specified element

Before Java 7, it was possible to add null elements to an empty TreeSet.
However, that was considered a bug. Therefore, TreeSet no longer supports the addition of null.
(beacuse while adding element to treeset, it internally use comparator or comparable method ,if it is null object, will throw NPE.)

 Operations like add, remove and search take O(log n) time while operations like printing n elements in sorted order require O(n) time.
 
 A TreeSet should be our primary choice if we want to keep our entries sorted as a TreeSet may be accessed and traversed in either ascending or descending order
 
 
 
 HashTable
 =========
 Hashtable is the oldest implementation of a hash table data structure in Java.
 public class Hashtable<K,V>
    extends Dictionary<K,V>
    implements Map<K,V>, Cloneable, java.io.Serializable

 
 
 









 HashMap
=========
public class HashMap<K,V> extends AbstractMap<K,V>
    implements Map<K,V>, Cloneable, Serializable
	
HashMap also allows us to have null as a key
We can use any class as the key in our HashMap. However, for the map to work properly, we need to provide an implementation for equals() and hashCode().

map.forEach((k,v)-> System.out.println(k+""+v));
productsByName.getOrDefault("horse carriage", chocolate); 
productsByName.putIfAbsent("E-Bike", chocolate);
merge()-with merge(), we can modify the value for a given key if a mapping exists, or add a new value otherwise

compute()- With the compute() method, we can compute the value for a given key:

HashMap stores elements in so-called buckets and the number of buckets is called capacity. When we want to put a value in the map, HashMap calculates the bucket based on the key and stores the value in that bucket. To retrieve the value, HashMap calculates the bucket in exactly the same way.

For this to work correctly, equal keys must have the same hash, however, different keys can have the same hash. If two different keys have the same hash, the two values belonging to them will be stored in the same bucket. Inside a bucket, values are stored in a list and retrieved by looping over all elements. The cost of this is O(n).
As of Java 8 (see JEP 180), the data structure in which the values inside one bucket are stored is changed from a list to a balanced tree if a bucket contains 8 or more values, and it's changed back to a list if, at some point, only 6 values are left in the bucket. This improves the performance to be O(log n).

Differences Between HashMap and Hashtable
------------------------------------------
Neither class maintains the insertion order of the elements. In other words, the first item added may not be the first item when we iterate over the values.

Null as key
Synchronization
faster 
memory - hashmap take less memory
Iteration Over Elements(HashMap uses Iterator to iterate over values, whereas Hashtable has Enumerator for the same. )
 Iterator has a remove() method to remove elements from underlying collections, on cass Enumerator we can't remove.
 
 Iterator<String> iterator = map.keySet().iterator();
		while(iterator.hasNext()){ 
		    String key=iterator.next();
		    //map.put("key4", "value4"); // will throw ConcurrentModificationException
		    if("key1".equals(key))
		       iterator.remove(); // it will remove the entry from map
               map.remove(key); //also throw ConcurrentModificationException
		}



 LinkedHashMap 
 ==============
 public class LinkedHashMap<K,V>
    extends HashMap<K,V>
    implements Map<K,V>
	
the linked hash map is based on both hash table and linked list to enhance the functionality of hash map.
It maintains a doubly-linked list running through all its entries in addition to an underlying array of default size 16.

To maintain the order of elements, the linked hashmap modifies the Map.Entry class of HashMap by adding pointers to the after and before entries

static class Entry<K,V> extends HashMap.Node<K,V> {
        Entry<K,V> before, after;
        Entry(int hash, K key, V value, Node<K,V> next) {
            super(hash, key, value, next);
        }
    }
Notice that the Entry class simply adds two pointers; before and after which enable it to hook itself to the linked list. it maintaining insertion order.

LinkedHashMap<Integer, String> map = new LinkedHashMap<>(16, .75f, false);

The first parameter is the initial capacity, followed by the load factor and the last param is the ordering mode.(default ordering mode is insertion order).

the order of elements in the key set is transformed as we perform access operations on the map.

if you pass accessOrder=true , then it follow LRU (Least Recently Use )
Map<Integer,String> map=new LinkedHashMap<>(16, .75f, true);


Set<Integer> keys = map.keySet();
assertEquals("[1, 2, 3, 4, 5]", keys.toString());
map.get(4);
assertEquals("[1, 2, 3, 5, 4]", keys.toString());
map.get(1);
assertEquals("[2, 3, 5, 4, 1]", keys.toString());
map.get(3);
assertEquals("[2, 5, 4, 1, 3]", keys.toString());

RemoveEldestEntry
-----------------
public class MyLinkedHashMap<K, V> extends LinkedHashMap<K, V> {
 
    private static final int MAX_ENTRIES = 5;
 
    public MyLinkedHashMap(
      int initialCapacity, float loadFactor, boolean accessOrder) {
        super(initialCapacity, loadFactor, accessOrder);
    }
 
    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        return size() > MAX_ENTRIES;
    }
}

LinkedHashMap<Integer, String> map
      = new MyLinkedHashMap<>(16, .75f, true);
map.put(1, null);
map.put(2, null);
map.put(3, null);
map.put(4, null);
map.put(5, null);
Set<Integer> keys = map.keySet();
assertEquals("[1, 2, 3, 4, 5]", keys.toString());

map.put(6, null);
assertEquals("[2, 3, 4, 5, 6]", keys.toString());

map.put(7, null);
assertEquals("[3, 4, 5, 6, 7]", keys.toString());

map.put(8, null);
assertEquals("[4, 5, 6, 7, 8]", keys.toString());

Just like HashMap, LinkedHashMap performs the basic Map operations of add, remove and contains in constant-time, as long as the hash function is well-dimensioned. It also accepts a null key as well as null values.













TreeMap
========
public class TreeMap<K,V> extends AbstractMap<K,V>
  implements NavigableMap<K,V>, Cloneable, java.io.Serializable
  
TreeMap is a map implementation that keeps its entries sorted according to the natural ordering of its keys or better still using a comparator if provided by the user at construction time.

TreeMap, unlike a hash map and linked hash map, does not employ the hashing principle anywhere since it does not use an array to store its entries.

Integer highestKey = map.lastKey(); 
Integer lowestKey = map.firstKey();
map.headMap(3)
map.tailMap(3)

it is based on Red-Black tree principle
Red-black tree is a self-balancing binary search tree
operations like search, get, put and remove take logarithmic time O(log n).
 tree map is not synchronized 



 WeakHashMap
 ===========
 public class WeakHashMap<K,V>
    extends AbstractMap<K,V>
    implements Map<K,V> {
 WeakHashMap is a hashtable-based implementation of the Map interface, with keys that are of a WeakReference type.
 An entry in a WeakHashMap will automatically be removed when its key is no longer in ordinary use, meaning that there is no single Reference that point to that key. When the garbage collection (GC) process discards a key, its entry is effectively removed from the map, so this class behaves somewhat differently from other Map implementations.

 Strong References
 ----------------
 Integer prime = 1;
 Any object which has a strong reference pointing to it is not eligible for GC.
Soft References
--------------
 Integer prime = 1;  
SoftReference<Integer> soft = new SoftReference<Integer>(prime); 
prime = null;
we are wrapping prime strong reference into a soft reference. After making that strong reference null, a prime object is eligible for GC but will be collected only when JVM absolutely needs memory.
Weak References
------------
The objects that are referenced only by weak references are garbage collected eagerly; the GC won't wait until it needs memory in that case.
Integer prime = 1;  
WeakReference<Integer> soft = new WeakReference<Integer>(prime); 
prime = null;
When we made a prime reference null, the prime object will be garbage collected in the next GC cycle

WeakHashMap<UniqueImageName, BigImage> map = new WeakHashMap<>();
BigImage bigImage = new BigImage("image_id");
UniqueImageName imageName = new UniqueImageName("name_of_big_image");
 
map.put(imageName, bigImage);
assertTrue(map.containsKey(imageName));
 
imageName = null;
System.gc();
 
await().atMost(10, TimeUnit.SECONDS).until(map::isEmpty)


 EnumMap
 =======
 public class EnumMap<K extends Enum<K>, V> extends AbstractMap<K, V>
    implements java.io.Serializable, Cloneable

 EnumMap is a Map implementation that exclusively takes Enum as its keys.
public enum DayOfWeek {
    MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY, SUNDAY
} 

 EnumMap<DayOfWeek, String> activityMap = new EnumMap<>(DayOfWeek.class);
activityMap.put(DayOfWeek.MONDAY, "Soccer");

 EnumMap requires the key type in the constructor.

convert non-enum map to enumMap
Map<DayOfWeek, String> ordinaryMap = new HashMap();
ordinaryMap.put(DayOfWeek.MONDAY, "Soccer");
 
EnumMap enumMap = new EnumMap(ordinaryMap);
assertThat(enumMap.size()).isEqualTo(1);
Note that the map must be non-empty so that EnumMap can determine the key type from an existing entry.

EnumMap is an ordered map . it depend up on which order you  define enum constants.
Collection Views
-----
Collection values = dayMap.values();
Set keys = dayMap.keySet();
dayMap.entrySet()

remember that any changes we make in the original activity map will be reflected in any of its views:
Collection values = dayMap.values();
activityMap.put(DayOfWeek.TUESDAY, "Basketball");
assertThat(values)
    .containsExactly("Soccer", "Basketball", "Hiking", "Karate");

Using Enum as key makes it possible to do some extra performance optimization, like a quicker hash computation since all possible keys are known in advance.
EnumMap is an ordered map, in that its views will iterate in enum order.

Immutable Map
=============
An Unmodifiable Map is just a wrapper over a modifiable map and it doesn't allow modifications to it directly
Map<String, String> mutableMap = new HashMap<>();
mutableMap.put("USA", "North America");
 
Map<String, String> unmodifiableMap = Collections.unmodifiableMap(mutableMap);
assertThrows(UnsupportedOperationException.class,
  () -> unmodifiableMap.put("Canada", "North America"));

But the underlying mutable map can still be changed and the modifications are reflected in the Unmodifiable map as well:

mutableMap.remove("USA");
assertFalse(unmodifiableMap.containsKey("USA"));
         
mutableMap.put("Mexico", "North America");
assertTrue(unmodifiableMap.containsKey("Mexico"));


Map Initalization
-------
Collections.singletonMap("username1", "password1")
this map is immutable, if we try to add more entries, it'll throw java.lang.UnsupportedOperationException.
create an immutable empty map 
Map<String, String> emptyMap = Collections.emptyMap();

Map<String, String> map = Stream.of(new String[][] {
  { "Hello", "World" }, 
  { "John", "Doe" }, 
}).collect(Collectors.toMap(data -> data[0], data -> data[1]));

Map<String, Integer> map = Stream.of(
  new AbstractMap.SimpleEntry<>("idea", 1), 
  new AbstractMap.SimpleEntry<>("mobile", 2))
  .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));


Map Merge
---------
Map<String,String> map1=new HashMap<>();
        map1.put("jame1","india1");
        map1.put("bond1","england1");
        map1.put("key1","value1");
        Map<String,String> map2=new HashMap<>();
        map2.put("jame1","india2");
        map2.put("bond1","england2");       
        BiFunction<String,String, String> fun=(e1,e2)->e1+e2;
        map2.forEach((k,v)->map1.merge(k,v,fun));
        map1.forEach((k,v)->System.out.println(k+" "+v));
        String demo=map1.merge("key1","demo",(v1,v2)->v1+v2);
        System.out.println(demo); // it will print value1demo

Map<String,String> combine=Stream.concat(map1.entrySet().stream(),map2.entrySet().stream())
                .collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue,(v1,v2)->v1+v2));
        combine.forEach((k,v)->System.out.println(k+"  "+v));


Map<String, String> map3 = Stream.of(map1, map2)
  .flatMap(map -> map.entrySet().stream())
  .collect(Collectors.toMap(
    Map.Entry::getKey,
    Map.Entry::getValue,
    (v1, v2) -> v1+v2));

Map<String,String> map3 = map2.entrySet()
  .stream()
  .collect(Collectors.toMap(
    Map.Entry::getKey,
    Map.Entry::getValue,
    (v1, v2) -> v1+v2,
  () -> new HashMap<>(map1)));



Sort on HashMap
----------------
a)Using a TreeMap
TreeMap<String, Employee> sorted = new TreeMap<>(map); or
TreeMap<String, Employee> sorted = new TreeMap<>();
sorted.putAll(map);

b)Using Lambdas And Streams
map.entrySet()
  .stream()
  .sorted(Map.Entry.<String, Employee>comparingByKey())
  .forEach(System.out::println);

comparing by value and create new map
Map<String, Employee> result = map.entrySet()
  .stream()
  .sorted(Map.Entry.comparingByValue())
  .collect(Collectors.toMap(
    Map.Entry::getKey, 
    Map.Entry::getValue, 
    (oldValue, newValue) -> oldValue, LinkedHashMap::new));



Queue
=======
offer() – Inserts a new element onto the Queue
poll() – Removes an element from the front of the Queue
peek() – Inspects the element at the front of the Queue, without removing it

for design customize queue then extends AbstractQueue 
public class CustomBaeldungQueue<T> extends AbstractQueue<T> {
 
    private LinkedList<T> elements;
 
    public CustomBaeldungQueue() {
      this.elements = new LinkedList<T>();
    }
 
}
Java offers ConcurrentLinkedQueue, ArrayBlockingQueue, and ConcurrentLinkedDeque which are thread-safe and perfect for multi-threaded programs.

ArrayDeque
===========
Array Double Ended Queue
special kind of a growable array that allows us to add or remove an element from both sides.
An ArrayDeque implementation can be used as a Stack (Last-In-First-Out) or a Queue(First-In-First-Out).
The first group consists of methods that throw exception if the operation fails. The other group returns a status or a value:

Operation   Method  Method throwing Exception
Insertion from Head offerFirst(e)   addFirst(e)
Removal from Head   pollFirst() removeFirst()
Retrieval from Head peekFirst() getFirst()
Insertion from Tail offerLast(e)    addLast(e)
Removal from Tail   pollLast()  removeLast()
Retrieval from Tail peekLast()  getLast()

Using ArrayDeque as a Stack
---------
Deque<String> stack = new ArrayDeque<>();
    stack.push("first");
    stack.push("second");  
    assertEquals("second", stack.getFirst()); 
or 
 Deque<String> stack = new ArrayDeque<>();
    stack.push("first");
    stack.push("second");
    assertEquals("second", stack.pop()) 
Using ArrayDeque as a Queue
----------
Deque<String> queue = new ArrayDeque<>();
    queue.offer("first");
    queue.offer("second");
assertEquals("second", queue.getLast());
or
Deque<String> queue = new ArrayDeque<>();
    queue.offer("first");
    queue.offer("second");
    assertEquals("first", queue.poll());

Think own way, how internal ArrayDeque is working as both stack and queue.( hint: inital tail and head are started from middle index of array )
 
It's not thread-safe
Null elements are not accepted
Works significantly faster than the synchronized Stack
Is a faster queue than LinkedList due to the better locality of reference
Most operations have amortized constant time complexity
An Iterator returned by an ArrayDeque is fail-fast
ArrayDeque automatically doubles the size of an array when head and tail pointer meets each other while adding an element

Convert List to Array (Vice versa)
---------------------------------
List<Integer> sourceList = Arrays.asList(0, 1, 2, 3, 4, 5);
    Integer[] targetArray = sourceList.toArray(new Integer[sourceList.size()]);

Convert Set to Array (Vice versa)
---------------------------------
Integer[] sourceArray = { 0, 1, 2, 3, 4, 5 };
Set<Integer> targetSet = new HashSet<Integer>(Arrays.asList(sourceArray));
Alternatively,
 Set<Integer> targetSet = new HashSet<Integer>();
Collections.addAll(targetSet, sourceArray);
converting an existing Set to an array
Integer[] targetArray = sourceSet.toArray(new Integer[sourceSet.size()]);

Convert Set to List (Vice versa)
---------------------------------
List<Integer> sourceList = Arrays.asList(0, 1, 2, 3, 4, 5);
    Set<Integer> targetSet = new HashSet<>(sourceList);
List<Integer> targetList = new ArrayList<>(sourceSet);

Convert a Map to an Array, List or Set
---------------------------------------
Map<Integer, String> sourceMap = createMap();
     Collection<String> values = sourceMap.values();
    String[] targetArray = values.toArray(new String[values.size()]);

Map<Integer, String> sourceMap = createMap();
     List<String> targetList = new ArrayList<>(sourceMap.values());

Map<Integer, String> sourceMap = createMap();
     Set<String> targetSet = new HashSet<>(sourceMap.values());

Convert List to Map
--------------------
Map<Integer, Animal> map = list.stream()
      .collect(Collectors.toMap(Animal::getId, animal -> animal));

Convert a Map to a String
-------------------------
String mapAsString = map.keySet().stream()
      .map(key -> key + "=" + map.get(key))
      .collect(Collectors.joining(", ", "{", "}"));

The Difference Between Collection.stream().forEach() and Collection.forEach()
-------------------------------
processing order of the items is defined. In contrast, the processing order of Collection.stream().forEach() is undefined.
list.forEach(System.out::print);//insertion order
list.parallelStream().forEach(System.out::print);//random order

forEach() uuses the custom iterator, while stream().forEach() simply takes elements one by one from the list, ignoring the iterator.

Consumer<String> removeElement = s -> {
    System.out.println(s + " " + list.size());
    if (s != null && s.equals("A")) {
        list.remove("D");
    }
};

list.forEach(removeElement); // will throw ConcurrentModificationException middle fo the loop ,due to fail-fast
list.stream().forEach(removeElement);
// wiil throw ConcurrentModificationException  end of the loop

Sorting in Java
----------------
Arrays.sort(arrayToSort);
Arrays.sort(toSort,fromIndex,toIndex);//partial sort
Arrays.parallelSort(toSort);

Collections.sort(toSortList);

List<Integer> list = new ArrayList<Integer>(integersSet);
Collections.sort(list;
integersSet = new LinkedHashSet<>(list);

Shuffling Collections
---------------------
List<String> students = Arrays.asList("Foo", "Bar", "Baz", "Qux");
Collections.shuffle(students);

List<Map.Entry<Integer, String>> shuffledStudentEntries
 = new ArrayList<>(studentsById.entrySet());
Collections.shuffle(shuffledStudentEntries);
Map<Integer,String> aftershuffle=shuffledStudentEntries.stream()
        .collect(Collectors.toMap(Map.Entry::getKey,Map.Entry::getValue,(v1,v2)->v1,
                ()->new LinkedHashMap<>()));
aftershuffle.entrySet().forEach(System.out::println);

Zipping 
-------
IntStream
  .range(0, Math.min(names.size(), ages.size()))
  .mapToObj(i -> names.get(i) + ":" + ages.get(i))
Java Stream to an Immutable Collection
-------------
List<String> givenList = Arrays.asList("a", "b", "c");
    List<String> result = givenList.stream()
      .collect(collectingAndThen(toList(), ImmutableList::copyOf));
Size of an Iterable
-------------------
if (data instanceof Collection) {
    return ((Collection<?>) data).size();
}
using stream
return StreamSupport.stream(data.spliterator(), false).count();

Removing Elements from Java Collections
---------------------------------------
Iterator<String> i = names.iterator();
 while(i.hasNext()) {
    String e = i.next();
    if (e.startsWith("A")) {
        i.remove();
    }
}
using stream , names.removeIf(e -> e.startsWith("A"));

Collection<String> filteredCollection = names
  .stream()
  .filter(e -> !e.startsWith("A"))
  .collect(Collectors.toList());

alternatively
Map<Boolean, List<String>> classifiedElements = names
    .stream()
    .collect(Collectors.partitioningBy((String e) -> 
      !e.startsWith("A")));




===================================================================================================
String[] strArray = new String[] { "John", "Snow" };
ArrayList<String> strList = (ArrayList<String>) Arrays.asList(strArray);
System.out.println("String list: " + strList);
he reason is that although the static method Arrays.asList() returns a List, we don't know until runtime exactly what implementation is returned. So at compile time the compiler can't know either and allows the cast.
When the code runs, the actual implementation is checked which finds that Arrays.asList() returns an Arrays$List thus causing a ClassCastException.

public static List asList(T... a)

    a fixed-size List as of size of a given array
    an element of the same type as the one in the original array and it must be an Object
    elements in the same order as in original array
    a list that is serializable and implements RandomAccess
Since the returned List is a fixed-size List, we can’t add/remove elements.
An attempt to add more elements would cause UnsupportedOperationException

Collections.emptyList() returns a list (java.util.Collections.EmptyList) that can't be modified and An attempt to add more elements would cause UnsupportedOperationException.

Collections.frequency(list,"james") //This method returns the number of elements in a Collection c matching an Object o.

 String result = intList.stream()
      .map(n -> String.valueOf(n))
      .collect(Collectors.joining("-", "{", "}"));

Converting Iterable to Collection
----------------------------
Iterable<String> iterable = Arrays.asList("john", "tom", "jane");
List<String> result = 
  StreamSupport.stream(iterable.spliterator(), false)
    .collect(Collectors.toList());

Converting Iterator to Collection
----------------------------
List<String> result = 
  StreamSupport.stream(Spliterators.spliteratorUnknownSize(iterator, Spliterator.ORDERED), false)
    .collect(Collectors.toList());
	
List<Integer> actualList = StreamSupport
  .stream(iterable.spliterator(), false)
  .collect(Collectors.toList());
 
Array to String Conversions
----------------------
String[] strArray = { "one", "two", "three" };
String joinedString = Arrays.toString(strArray);
String joinedString = String.join("", new String[]{ "Convert", "With", "Java", "Streams" });
String joinedString = Arrays
    .stream(new String[]{ "Convert", "With", "Java", "Streams" })
    .collect(Collectors.joining());

Set operations
--------------
Set<Integer> intersectSet = new HashSet<>(setA);
intersectSet.retainAll(setB); // it will return intersection between setA and setB
Set<Integer> unionSet = new HashSet<>(setA);
unionSet.addAll(setB); // return union between setA and setB
Set<Integer> differenceSet = new HashSet<>(setA);
differenceSet.removeAll(setB); return A-B
using stream
Set<Integer> intersectSet = setA.stream()
    .filter(setB::contains)
    .collect(Collectors.toSet()); // A instersection Bar

Set<Integer> unionSet = Stream.concat(setA.stream(), setB.stream())
    .collect(Collectors.toSet()); // A union Bar
Set<Integer> differenceSet = setA.stream()
    .filter(val -> !setB.contains(val))
    .collect(Collectors.toSet()); // return A-B

HashSet and TreeSet Comparison
-------------------------------
HashSet stores the objects in random order, whereas TreeSet applies the natural order of the elements.
HashSet can store null objects, while TreeSet does not allow them:
HashSet provides constant-time performance for most operations like add(), remove() and contains(), versus the log(n) time offered by the TreeSet. 

TreeSet is rich in functionalities, implementing additional methods like:
pollFirst() – to return the first element, or null if Set is empty
    pollLast() – to retrieve and remove the last element, or return null if Set is empty
    first() – to return the first item
    last() – to return the last item
    ceiling() – to return the least element greater than or equal to the given element, or null if there is no such element
    lower() – to return the largest element strictly less than the given element, or null if there is no such element

If we want to keep our entries sorted, we need to go for the TreeSet
If we cpu performance more than memory consumption, we should go for the HashSet
If we are short on memory, we should go for the TreeSet
HashSet‘s performance can be tuned using the initialCapacity and loadFactor, which is not possible for the TreeSet

create HashSet using stream
----------
Set<String> set = Stream.of("a", "b", "c")
  .collect(Collectors.toCollection(HashSet::new));

Arrays.sort(Object[]) needs to compare one object against another, it needs to call each element's compareTo method.
Arrays.sort(int[]) can simply use primitive relational operators like < and >, which are single bytecode instructions.

key differences of ArrayList and Vector.
---------------------------------------
    synchronization – The first major difference between these two. Vector is synchronized and ArrayList isn't.
    size growth – Another difference between the two is the way they resize while reaching their capacity. The Vector doubles its size. In contrast, ArrayList increases only by half of its length
    iteration – And Vector can use Iterator and Enumeration to traverse over the elements. On the other hand, ArrayList can only use Iterator.
    performance – Largely due to synchronization, Vector operations are slower when compared to ArrayList
    framework – Also, ArrayList is a part of the Collections framework and was introduced in JDK 1.2. Meanwhile, Vector is present in the earlier versions of Java as a legacy class.
Differences Between Hashtable and HashMap
-----------------------------------------
Synchronization
 Hashtable doesn't allow null at all
 Hashtable<String, String> table = new Hashtable<String, String>();
table.put("key", null); will throw NullPointerException.
table.put(null, "value"); will throw NullPointerException
HashMap uses Iterator, whereas Hashtable has Enumerator for the same.
since JDK 1.8, Hashtable has been deprecated. However, ConcurrentHashMap is a great Hashtable replacement
Differences Between Collection.clear() and Collection.removeAll()
----------------------------------------------
Collection<Integer> collection = new ArrayList<>(Arrays.asList(1, 2, 3, 4, 5));
collection.clear();
assertTrue(collection.isEmpty()); 
Collection<Integer> secondCollection = new ArrayList<>(
      Arrays.asList(3, 4, 5, 6, 7));
collection.removeAll(secondCollection); // it wiill remove 3,4,5

Performance of contains() in a HashSet vs ArrayList
--------------------------------------------------
the contains() of HashSet runs in O(1) time. Getting the object's bucket location is a constant time operation. Taking into account possible collisions, the lookup time may rise to log(n) because the internal bucket structure is a TreeMap.
Internally, ArrayList uses the indexOf(object) method to check if the object is in the list. The indexOf(object) method iterates the entire array and compares each element with the equals(object) method.

Fail-Safe Iterator vs Fail-Fast Iterator
------------------------------------------
Fail-Fast systems abort operation as-fast-as-possible exposing failures immediately and stopping the whole operation.
Fail-Safe systems don't abort an operation in the case of a failure. Such systems try to avoid raising failures as much as possible.
Default iterators for Collections from java.util package such as ArrayList, HashMap, etc. are Fail-Fast.
Iterator<Integer> iterator = numbers.iterator();
while (iterator.hasNext()) {
    Integer number = iterator.next();
    numbers.add(50);// will throw throw ConcurrentModificationException 
	iterator.remove(); //  an item is removed using Iterator‘s remove() method, that's entirely safe and doesn't throw an exception.
}
In case of Fail-Safe Iterators, Those iterators create a clone of the actual Collection and iterate over it. If any modification happens after the iterator is created, the copy still remains untouched. Hence, these Iterators continue looping over the Collection even if it's modified.
One disadvantage is that the Iterator isn't guaranteed to return updated data from the Collection, as it's working on the clone instead of the actual Collection.Another disadvantage is the overhead of creating a copy of the Collection, both regarding time and memory.
Iterators on Collections from java.util.concurrent package such as ConcurrentHashMap, CopyOnWriteArrayList, etc. are Fail-Safe in nature.

Copying a HashMap
------------------
A shallow copy of a HashMap is a new HashMap with mappings to the same key and value objects as the original HashMap.
HashMap<String, Employee> shallowCopy =(HashMap<String, Employee>) originalMap.clone()
HashMap<String, Employee> shallowCopy = new HashMap<String, Employee>(originalMap);
create a shallow copy of a HashMap using stream API
HashMap<String, Employee> shallowCopy=originalMap.entrySet().stream()
  .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
 because this is a shallow copy, if we change an Employee instance's properties, it will affect both the original map and its shallow copy.

A deep copy of a HashMap is a new HashMap that deeply copies all the mappings. Therefore, it creates new objects for all keys, values, and mappings. explicitly modifying the mappings (key-values) will not affect the deep copy.

Arrays.stream(char[]) is not allow
-----------------------------------
There are only 3 types of primitive streams - IntStream, LongStream and DoubleStream.

As a result, Arrays has methods that convert int[], long[] and double[] to the corresponding primitive streams.

There are no corresponding methods for boolean[], byte[], short[], char[] and float[], since these primitive types have no corresponding primitive streams.

public Map<String, Long> countChars(String input) {
    Map<String, Long> frequentChars = Arrays.stream(input.toLowerCase().split(""))
            .collect(Collectors.groupingBy(c -> c, Collectors.counting()));
    frequentChars.forEach((k, v) -> System.out.println(k + ":" + v));
    return frequentChars;
}



groupingBy Collector
=====================
static <T,K> Collector<T,?,Map<K,List<T>>> 
  groupingBy(Function<? super T,? extends K> classifier) // by default it return Map<K,List<T>>
--------------
Map<BlogPostType, List<BlogPost>> postsPerType = posts.stream()
  .collect(groupingBy(BlogPost::getType));
  
 Grouping by Multiple Fields
Map<String, Map<BlogPostType, List>> map = posts.stream()
  .collect(groupingBy(BlogPost::getAuthor, groupingBy(BlogPost::getType)));


 
  
static <T,K,A,D> Collector<T,?,Map<K,D>>
  groupingBy(Function<? super T,? extends K> classifier, 
    Collector<? super T,A,D> downstream) //return Map<K,List<T> or Set<T> or Long or aggration result or averagingInt or averagingInt or maxBy or summarizingInt
-----------------------
Map<BlogPostType, Set<BlogPost>> postsPerType = posts.stream()
  .collect(groupingBy(BlogPost::getType, toSet()));	
 
 Map<String,String> map=list.stream().collect(Collectors				.groupingBy(Person::getAge,Collectors.mapping(Person::getName,Collectors.joining(",","[","]"))));
System.out.println(map); //{30=[bairagi1,bairagi3], 31=[bairagi2], 32=[bairagi4]}



static <T,K,D,A,M extends Map<K,D>> Collector<T,?,M>
  groupingBy(Function<? super T,? extends K> classifier, 
    Supplier<M> mapFactory, Collector<? super T,A,D> downstream)
----------------------------
Map<String,Set<Person>> map1=
				list.stream().collect(Collectors
				.groupingBy(Person::getAge,TreeMap::new,Collectors.toSet()));	
				

collect() method on java stream
===============================
<R, A> R collect(Collector<? super T, A, R> collector)
----------------------
Stream<String> strS=Stream.of("bairagi","nath","behera");
List<String> slist=strS.collect(Collectors.toList());
System.out.println(slist); //[bairagi, nath, behera]


<R> R collect(Supplier<R> supplier,BiConsumer<R, ? super T> accumulator, BiConsumer<R, R>combiner)
------------------
List<String> slist=strS.collect(LinkedList::new,LinkedList::add,LinkedList::addAll);
System.out.println(slist); //[bairagi, nath, behera]

The combiner is used when your Stream is parallel, since in that case several threads collect elements of the Stream into sub-lists of the final output ArrayList, and these sub-lists have to be combined to produce the final ArrayList
	
	
	
	
	
java.util.Arrays APIs
======================
String[] intro = new String[] { "once", "upon", "a", "time" };
String[] abridgement = Arrays.copyOfRange(storyIntro, 0, 3); //beginning index (inclusive) and end index (exclusive) 
String[] revised = Arrays.copyOf(intro, 3); //// take intro and a target array size and we'd get back a new array of that length:

String[] expanded = Arrays.copyOf(intro, 5);//copyOf pads the array with nulls if our target size is bigger than the original size.

String[] stutter = new String[3];
Arrays.fill(stutter, "once"); //ill, which is useful when we want an array where all elements are the same . Note : ill, which is useful when we want an array where all elements are the same

equals and deepEquals
----------------------
assertTrue(
  Arrays.equals(new String[] { "once", "upon", "a", "time" }, intro));
assertFalse(
  Arrays.equals(new String[] { "once", "upon", "a", null }, intro));
  
we can use deepEquals to not only check the top-level elements but also perform the check recursively
Object[] story = new Object[] 
  { intro, new String[] { "chapter one", "chapter two" }, end };
Object[] copy = new Object[] 
  { intro, new String[] { "chapter one", "chapter two" }, end };
 
assertTrue(Arrays.deepEquals(story, copy));
assertFalse(Arrays.equals(story, copy));

This is because deepEquals ultimately calls itself each time it encounters an array, while equals will simply compare sub-arrays' references.
Also, this makes it dangerous to call on an array with a self-reference!

hashCode and deepHashCode
--------------------------
Object[] looping = new Object[]{ intro, intro }; 
int hashBefore = Arrays.hashCode(looping);
int deepHashBefore = Arrays.deepHashCode(looping);
intro[3] = null;
int hashAfter = Arrays.hashCode(looping);
int deepHashAfter = Arrays.deepHashCode(looping);
assertEquals(hashAfter, hashBefore);
assertNotEquals(deepHashAfter, deepHashBefore);
deepHashCode is the underlying calculation used when we are working with data structures like HashMap and HashSet on arrays.
Sort
-----
If our elements are either primitives or they implement Comparable, we can use sort to perform an in-line sort.
Arrays.sort(sorted);
sort will use a different algorithm for different array element types. Primitive types use a dual-pivot quicksort and Object types use Timsort. Both have the average case of O(n log(n)) for a randomly-sorted array.As of Java 8, parallelSort is available for a parallel sort-merge.  It offers a concurrent sorting method using several Arrays.sort tasks.

binarySearch
-------------
int firstIndex = Arrays.binarySearch(sorted, "time");
int firstIndexWithCase = Arrays.binarySearch(sorted, "TiMe", String::compareToIgnoreCase);//If we don't provide a Comparator as a third parameter, then binarySearch counts on our element type being of type Comparable.

Stream 
-------
Arrays.stream(intro, startInclusive,endExclus).count(); // will Throws ArrayIndexOutOfBound exception if index are not in the range.

toString and deepToString
-------------------------
assertEquals("[once, upon, a, time]", Arrays.toString(storyIntro));

assertEquals(
  "[[once, upon, a, time], [chapter one, chapter two], [the, end]]",
  Arrays.deepToString(story)); // we can direct covert 2d array to String by using deepToString
 
 asList
 -------
 List<String> rets = Arrays.asList(storyIntro);
 However, the returned List will be a fixed length so we won't be able to add or remove elements.Note also that, curiously, java.util.Arrays has its own ArrayList subclass, which asList returns. This can be very deceptive when debugging!
 
 setAll
 -------
  String[] longAgo = new String[4];
    Arrays.setAll(longAgo, i -> String.valueOf(i+1)); 
    System.out.println(Arrays.toString(longAgo));

parallelPrefix on java 8
------------------------
int[] arr = new int[] { 1, 2, 3, 4};
Arrays.parallelPrefix(arr, (left, right) -> left + right); // as like reduce method
assertThat(arr, is(new int[] { 1, 3, 6, 10}));
Arrays.parallelPrefix(arri, 1, 4, (left, right) -> left + right); // you can apply on sub array also
the method is performed in parallel, so the cumulative operation should be side-effect-free and associative. // we should write to code in such way that that make data consistancy.

Join Two Arrays
----------------
String[] result = Stream.concat(
      Arrays.stream(animals1), Arrays.stream(animals2)).toArray(String[]::new);
	  
	 
System arraycopy
----------------
public static native void arraycopy(Object src,  int  srcPos,
                                        Object dest, int destPos,
                                        int length);
										
										
String APIs
============
join method introduced on java 8
String newLine = System.getProperty("line.separator");
		String names[]={"bairagi","nath","behera"};
		String out=String.join(newLine,names);
		System.out.println(out);
		out=String.join("|",names);
		System.out.println(out);
		
StringWriter is another method that we can utilize to create a multi-line string. We don't need newLine here, because we use PrintWriter. The println function automatically adds new lines:

public String stringWriter() {
    StringWriter stringWriter = new StringWriter();
    PrintWriter printWriter = new PrintWriter(stringWriter);
    printWriter.println("Get busy living");
    printWriter.println("or");
    printWriter.println("get busy dying.");
    printWriter.println("--Stephen King");
    return stringWriter.toString();
}
Both String#isEmpty and String#length can be used to check for empty strings.
trim()- trim space on both ends

String[] splitted = "192.168.1.178".split("\\.") // split by "."

String[] splitted = "b a, e, l.d u, n g-to".split("[,.-]");
or
String[] splitted = "b a, e, l.d u, n g".split("\\s+|,\\s*|\\.\\s*"));

CharSequence vs. String in Java
--------------------------------
CharSequence is an interface that represents a sequence of characters.both mutable and immutable classes implement this interface. ex; Stinrg class implemented as immutable and StringBuilder,StringBuffer are implemented as mutable.

an interface can't be instantiated directly
CharSequence charSequence new String("bairagi"); // we can't instantion with String new Operator
CharSequence charSequence1="bairagi";
CharSequence charSequence1 = new StringBuffer("baeldung");
CharSequence charSequence2 = new StringBuilder("baeldung");

This  interface does not imply a built-in comparison strategy, whereas the String class implements the Comparable<String> interface.

StringJoiner fruitJoiner = new StringJoiner(", ");( java 8 introduced  on java.util package)
fruitJoiner.add("Apples");
fruitJoiner.add("Oranges");
fruitJoiner.add("Bananas"); 
assertEquals("Apples, Oranges, Bananas", fruitJoiner.toString());

member variables are initialized with a default value when the class is constructed, null in String‘s case. But, we have to initialize local variables ourselves.

Convert char to String 
-----------------------
String.valueOf()
Character's Constructor //String result = new Character(givenChar).toString();
Implicit Cast to String Type //String result = givenChar + "";
String.format() //String result = String.format("%c", givenChar);

StringTokenizer
-----------------
public StringTokenizer(String str, String delim, boolean returnDelims){}
The StringTokenizer class helps us split Strings into multiple tokens
StringTokenizer st=new StringTokenizer("bairagi,nath,behera",",",false); // true means then StringTokenizer considers the delimiter itself as a token and add it to its internal pool of tokens.
		while(st.hasMoreTokens())
			System.out.println(st.nextToken());
		
StringTokenizer also comes with an overloaded nextToken() method which takes a string fragment as input. 
tokenizer.nextToken("e") // it will override next token with "e"


Convert Hex to ASCII vice versa
-------------------------------
private static String asciiToHex(String asciiStr) {
    char[] chars = asciiStr.toCharArray();
    StringBuilder hex = new StringBuilder();
    for (char ch : chars) {
        hex.append(Integer.toHexString((int) ch));
    }
 
    return hex.toString();
}


private static String hexToAscii(String hexStr) {
    StringBuilder output = new StringBuilder("");
     
    for (int i = 0; i < hexStr.length(); i += 2) {
        String str = hexStr.substring(i, i + 2);
        output.append((char) Integer.parseInt(str, 16));
    }
     
    return output.toString();
}

String APIs
-----------
Java String.String() Available Signatures
------------------------
public String()
public String(byte[] bytes)
public String(byte[] bytes, Charset charset)
public String(byte[] bytes, int offset, int length)
public String(byte[] bytes, int offset, int length, Charset charset)
public String(byte[] bytes, int offset, int length, String charsetName)
public String(byte[] bytes, String charsetName)
public String(char[] value)
public String(char[] value, int offset, int count)
public String(int[] codePoints, int offset, int count)
public String(String original)
public String(StringBuffer buffer)
public String(StringBuilder builder)

Java String.codePointCountthe number of Unicode code points in the specified range //the number of Unicode code points in the specified range

Java String.codePointAt(int index) //returns the code point at the specified index
Java String.concat()
Java String.contains(CharSequence s) //checks if a String contains another String
Java String.copyValueOf()
------
public static String copyValueOf(char[] data)
public static String copyValueOf(char[] data, int offset, int count)
char[] array = new char[] { 'a', 'b', 'c', 'd' };     
assertEquals("abcd", String.copyValueOf(array));

Java String.endsWith()
Java String.format()
Java String.getBytes()
----
    byte[] byteArray1 = "abcd".getBytes();
    byte[] byteArray2 = "efgh".getBytes(StandardCharsets.US_ASCII);
    byte[] byteArray3 = "ijkl".getBytes("UTF-8");
    byte[] expected1 = new byte[] { 97, 98, 99, 100 };
    byte[] expected2 = new byte[] { 101, 102, 103, 104 };
    byte[] expected3 = new byte[] { 105, 106, 107, 108 };     
    assertArrayEquals(expected1, byteArray1);
    assertArrayEquals(expected2, byteArray2);
    assertArrayEquals(expected3, byteArray3);
	
Java String.indexOf() //returns the first occurrence index of a character or a String in another String.
-----
public int indexOf(int ch)
public int indexOf(int ch, int fromIndex)
public int indexOf(String str)
public int indexOf(String str, int fromIndex)

Java String.intern()
Java String.isEmpty()
Java String.lastIndexOf()//returns the index of the last occurrence of a String in another String.
-----
public int lastIndexOf(int ch)
public int lastIndexOf(int ch, int fromIndex)
public int lastIndexOf(String str)


Java String.regionMatches() //checks if two String regions are equal.
-------
boolean regionMatches(int toffset, String other, int ooffset, int len)
boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len)

Java String.replace()
public String replace(CharSequence target, CharSequence replacement)
Java String.replaceAll() //replaces all occurrences of a String in another String.
------
public String replaceAll(String regex, String replacement)
Java String.split()
------
public String[] split(String regex, int limit)
public String[] split(String regex)

Java String.startsWith()
Java String.subSequence()
----
public CharSequence subSequence(int beginIndex, int endIndex)
same as substring().The only difference is that it returns a CharSequence instead of a String.

Java String.substring()
---
public String substring(int beginIndex)
public String substring(int beginIndex, int endIndex)

Java String.toLowerCase()
Java String.toUpperCase()
Java String.trim() //The method trim() removes any whitespace at the beginning and at the end of a String. If the String contains only spaces, then the method returns an empty String.

Java String.valueOf()
------
public static String valueOf(boolean b)
public static String valueOf(char c)
public static String valueOf(char[] data)
public static String valueOf(char[] data, int offset, int count) //
    offset – the index of the character to start converting from
    count – the number of characters to convert
public static String valueOf(double d)
public static String valueOf(float f)
public static String valueOf(int i)
public static String valueOf(long l)
public static String valueOf(Object obj)



		




